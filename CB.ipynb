{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Chatbots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The super basics\n",
    "\n",
    "Just to return whatever you say back to you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bot_template = \"BOT : {0}\"\n",
    "user_template = \"USER : {0}\"\n",
    "\n",
    "# Define a function that responds to a user's message: respond\n",
    "def respond(message):\n",
    "    # Concatenate the user's message to the end of a standard bot respone\n",
    "    bot_message = \"I can hear you! You said: \" + message\n",
    "    # Return the result\n",
    "    return(bot_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function that sends a message to the bot: send_message\n",
    "def send_message(message):\n",
    "    # Print user_template including the user_message\n",
    "    print(user_template.format(message))\n",
    "    # Get the bot's response to the message\n",
    "    response = respond(message)\n",
    "    # Print the bot template including the bot's response.\n",
    "    print(bot_template.format(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER : hello\n",
      "BOT : I can hear you! You said: hello\n"
     ]
    }
   ],
   "source": [
    "# Send a message to the bot\n",
    "send_message(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smalltalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "respones = {\n",
    "    \"what's your name?\": \"my name is EchoBot\",\n",
    "    \"what's the weather today?\": \"it's sunny!\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def respond(message):\n",
    "    if message in responses:\n",
    "        return(responses[message])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can insert a variable into a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "responses = {\n",
    "    \"what's today's weather?\": \"it's {} today\"\n",
    "}\n",
    "\n",
    "weather_today = \"cloudy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def respond(message):\n",
    "    if message in responses:\n",
    "        return(responses[message].format(weather_today))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"it's cloudy today\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respond(\"what's today's weather?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It gets boring if it's the same response over and over again. Let's generate a list of responses and randomly output them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "responses = {\n",
    "    \"what's your name?\": [\"my name is EchoBot\", \"they call me EchoBot\", \"the name's Bot...EchoBot\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def respond(message):\n",
    "    if message in responses:\n",
    "        return(random.choice(responses[message]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the name's Bot...EchoBot\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respond(\"what's your name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'they call me EchoBot'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respond(\"what's your name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asking questions to drill down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "responses = [\"tell me more!\", \"why do you think that?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def respond(message):\n",
    "    return(random.choice(responses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tell me more!'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respond(\"I think you're really great\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chitchat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define variables\n",
    "name = \"Greg\"\n",
    "weather = \"cloudy\"\n",
    "\n",
    "# Define a dictionary with the predefined responses\n",
    "responses = {\n",
    "  \"what's your name?\": \"my name is {0}\".format(name),\n",
    "  \"what's today's weather?\": \"the weather is {0}\".format(weather),\n",
    "  \"default\": \"default message\"\n",
    "}\n",
    "\n",
    "# Return the matching response if there is one, default otherwise\n",
    "def respond(message):\n",
    "    # Check if the message is in the responses\n",
    "    if message in responses:\n",
    "        # Return the matching message\n",
    "        bot_message = responses[message]\n",
    "    else:\n",
    "        # Return the \"default\" message\n",
    "        bot_message = responses[\"default\"]\n",
    "    return bot_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my name is Greg'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respond(\"what's your name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'default message'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respond(\"hi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding variety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = \"Greg\"\n",
    "weather = \"cloudy\"\n",
    "\n",
    "# Define a dictionary containing a list of responses for each message\n",
    "responses = {\n",
    "  \"what's your name?\": [\n",
    "      \"my name is {0}\".format(name),\n",
    "      \"they call me {0}\".format(name),\n",
    "      \"I go by {0}\".format(name)\n",
    "   ],\n",
    "  \"what's today's weather?\": [\n",
    "      \"the weather is {0}\".format(weather),\n",
    "      \"it's {0} today\".format(weather)\n",
    "    ],\n",
    "  \"default\": [\"default message\"]\n",
    "}\n",
    "\n",
    "# Use random.choice() to choose a matching response\n",
    "def respond(message):\n",
    "    # Check if the message is in the responses\n",
    "    if message in responses:\n",
    "        # Return a random matching response\n",
    "        bot_message = random.choice(responses[message])\n",
    "    else:\n",
    "        # Return a random \"default\" response\n",
    "        bot_message = random.choice(responses[\"default\"])\n",
    "    return bot_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'default message'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respond(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my name is Greg'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respond(\"what's your name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my name is Greg'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respond(\"what's your name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asking questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "responses = {'question': [\"I don't know :(\", 'you tell me!'],\n",
    " 'statement': ['tell me more!',\n",
    "  'why do you think that?',\n",
    "  'how long have you felt this way?',\n",
    "  'I find that extremely interesting',\n",
    "  'can you back that up?',\n",
    "  'oh wow!',\n",
    "  ':)']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def respond(message):\n",
    "    # Check for a question mark\n",
    "    if message.endswith(\"?\"):\n",
    "        # Return a random question\n",
    "        return random.choice(responses[\"question\"])\n",
    "    # Return a random statement\n",
    "    return random.choice(responses[\"statement\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER : what's today's weather?\n",
      "BOT : you tell me!\n",
      "USER : what's today's weather?\n",
      "BOT : you tell me!\n",
      "USER : I love building chatbots\n",
      "BOT : how long have you felt this way?\n",
      "USER : I love building chatbots\n",
      "BOT : how long have you felt this way?\n"
     ]
    }
   ],
   "source": [
    "# Send messages ending in a question mark\n",
    "send_message(\"what's today's weather?\")\n",
    "send_message(\"what's today's weather?\")\n",
    "\n",
    "# Send messages which don't end with a question mark\n",
    "send_message(\"I love building chatbots\")\n",
    "send_message(\"I love building chatbots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object; span=(0, 55), match='do you remember when you ate strawberries in the >\n"
     ]
    }
   ],
   "source": [
    "# the dot character matches any character\n",
    "# astericks means match 0 or more\n",
    "\n",
    "pattern = \"do you remember .*\"\n",
    "message = \"do you remember when you ate strawberries in the garden\"\n",
    "match = re.search(pattern, message)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "string matches\n"
     ]
    }
   ],
   "source": [
    "# check if string matches\n",
    "# if it doesn't, it return None\n",
    "\n",
    "if match:\n",
    "    print(\"string matches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pattern = \"if (.*)\"\n",
    "message = \"what would happen if bots took over the world\"\n",
    "match = re.search(pattern, message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "string matches\n"
     ]
    }
   ],
   "source": [
    "if match:\n",
    "    print(\"string matches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'if bots took over the world'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match.group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bots took over the world'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match.group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grammatical transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def swap_pronouns(phrase):\n",
    "    if \"I\" in phrase:\n",
    "        return(re.sub(\"I\", \"you\", phrase))\n",
    "    if \"my\" in phrase:\n",
    "        return(re.sub(\"my\", \"your\", phrase))\n",
    "    else:\n",
    "        return(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you walk my dog'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swap_pronouns(\"I walk my dog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rules = {'I want (.*)': ['What would it mean if you got {0}',\n",
    "  'Why do you want {0}',\n",
    "  \"What's stopping you from getting {0}\"],\n",
    " 'do you remember (.*)': ['Did you think I would forget {0}',\n",
    "  \"Why haven't you been able to forget {0}\",\n",
    "  'What about {0}',\n",
    "  'Yes .. and?'],\n",
    " 'do you think (.*)': ['if {0}? Absolutely.', 'No chance'],\n",
    " 'if (.*)': [\"Do you really think it's likely that {0}\",\n",
    "  'Do you wish that {0}',\n",
    "  'What do you think about {0}',\n",
    "  'Really--if {0}']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I want (.*)': ['What would it mean if you got {0}',\n",
       "  'Why do you want {0}',\n",
       "  \"What's stopping you from getting {0}\"],\n",
       " 'do you remember (.*)': ['Did you think I would forget {0}',\n",
       "  \"Why haven't you been able to forget {0}\",\n",
       "  'What about {0}',\n",
       "  'Yes .. and?'],\n",
       " 'do you think (.*)': ['if {0}? Absolutely.', 'No chance'],\n",
       " 'if (.*)': [\"Do you really think it's likely that {0}\",\n",
       "  'Do you wish that {0}',\n",
       "  'What do you think about {0}',\n",
       "  'Really--if {0}']}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define match_rule()\n",
    "def match_rule(rules, message):\n",
    "    response, phrase = \"default\", None\n",
    "    \n",
    "    # Iterate over the rules dictionary\n",
    "    for pattern, responses in rules.items():\n",
    "        # Create a match object\n",
    "        match = re.search(pattern, message)\n",
    "        if match is not None:\n",
    "            # Choose a random response\n",
    "            response = random.choice(responses)\n",
    "            if '{0}' in response:\n",
    "                phrase = match.group(1)\n",
    "    # Return the response and phrase\n",
    "    return(response, phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Why haven't you been able to forget {0}\", 'your last birthday')\n"
     ]
    }
   ],
   "source": [
    "# Test match_rule\n",
    "print(match_rule(rules, \"do you remember your last birthday\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make responses grammatically coherent, you'll want to transform the extracted phrases from first to second person and vice versa. In English, conjugating verbs is easy, and simply swapping \"I\" and 'you', \"my\" and \"your\" works in most cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your last birthday\n",
      "when me went to florida\n",
      "i had your own castle\n"
     ]
    }
   ],
   "source": [
    "# Define replace_pronouns()\n",
    "def replace_pronouns(message):\n",
    "\n",
    "    message = message.lower()\n",
    "    if 'me' in message:\n",
    "        # Replace 'me' with 'you'\n",
    "        return(re.sub(\"me\", \"you\", message))\n",
    "    if 'my' in message:\n",
    "        # Replace 'my' with 'your'\n",
    "        return(re.sub(\"my\", \"your\", message))\n",
    "    if 'your' in message:\n",
    "        # Replace 'your' with 'my'\n",
    "        return(re.sub(\"your\", \"my\", message))\n",
    "    if 'you' in message:\n",
    "        # Replace 'you' with 'me'\n",
    "        return(re.sub(\"you\", \"me\", message))\n",
    "\n",
    "    return message\n",
    "\n",
    "print(replace_pronouns(\"my last birthday\"))\n",
    "print(replace_pronouns(\"when you went to Florida\"))\n",
    "print(replace_pronouns(\"I had my own castle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define respond()\n",
    "def respond(message):\n",
    "    # Call match_rule\n",
    "    response, phrase = match_rule(rules, message)\n",
    "    if '{0}' in response:\n",
    "        # Replace the pronouns in the phrase\n",
    "        phrase = replace_pronouns(phrase)\n",
    "        # Include the phrase in the response\n",
    "        response = response.format(phrase)\n",
    "    return(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER : do you remember your last birthday\n",
      "BOT : Did you think I would forget my last birthday\n",
      "USER : do you think humans should be worried about AI\n",
      "BOT : No chance\n",
      "USER : I want a robot friend\n",
      "BOT : What would it mean if you got a robot friend\n",
      "USER : what if you could be anything you wanted\n",
      "BOT : Do you wish that me could be anything me wanted\n"
     ]
    }
   ],
   "source": [
    "# Send the messages\n",
    "send_message(\"do you remember your last birthday\")\n",
    "send_message(\"do you think humans should be worried about AI\")\n",
    "send_message(\"I want a robot friend\")\n",
    "send_message(\"what if you could be anything you wanted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding intents and entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natural Language Understanding (NLU): subfield of NLP and is usually concerned with transforming text into structured data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the regex approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r\"(hello|hey|hi)\", \"hey there!\") is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# however, \"hi\" matches up with \"which one?\"\n",
    "\n",
    "re.search(r\"(hello|hey|hi)\", \"which one?\") is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can prevent this with /b to prevent searches on either sides of the keywords\n",
    "re.search(r\"\\b(hello|hey|hi)\\b\", \"which one?\") is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r\"\\b(hello|hey|hi)\\b\", \"hey there!\") is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#   [] indicates a range of characters\n",
    "#   * indicates 0 or more occurences of this pattern\n",
    "#   {1} indicates 1 of these characters (capitalized word)\n",
    "pattern = re.compile(\"[A-Z]{1}[a-z]*\")\n",
    "\n",
    "message = \"\"\"\n",
    "Mary is a friend of mine,\n",
    "she studied at Oxford and\n",
    "now works at Google\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary', 'Oxford', 'Google']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern.findall(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intent classification with regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keywords = {'goodbye': ['bye', 'farewell'],\n",
    " 'greet': ['hello', 'hi', 'hey'],\n",
    " 'thankyou': ['thank', 'thx']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'goodbye': ['bye', 'farewell'],\n",
       " 'greet': ['hello', 'hi', 'hey'],\n",
       " 'thankyou': ['thank', 'thx']}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "responses = {'goodbye': ['bye', 'farewell'],\n",
    " 'greet': ['hello', 'hi', 'hey'],\n",
    " 'thankyou': ['thank', 'thx']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'goodbye': ['bye', 'farewell'],\n",
       " 'greet': ['hello', 'hi', 'hey'],\n",
       " 'thankyou': ['thank', 'thx']}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'goodbye': re.compile('bye|farewell'), 'greet': re.compile('hello|hi|hey'), 'thankyou': re.compile('thank|thx')}\n"
     ]
    }
   ],
   "source": [
    "# Define a dictionary of patterns\n",
    "patterns = {}\n",
    "\n",
    "# Iterate over the keywords dictionary\n",
    "for intent, keys in keywords.items():\n",
    "    # Create regular expressions and compile them into pattern objects\n",
    "    patterns[intent] = re.compile(\"|\".join(keys))\n",
    "    \n",
    "# Print the patterns\n",
    "print(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patterns = {'goodbye': re.compile(r'bye|farewell', re.UNICODE),\n",
    " 'greet': re.compile(r'hello|hi|hey', re.UNICODE),\n",
    " 'thankyou': re.compile(r'thank|thx', re.UNICODE)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'goodbye': re.compile(r'bye|farewell', re.UNICODE),\n",
       " 'greet': re.compile(r'hello|hi|hey', re.UNICODE),\n",
       " 'thankyou': re.compile(r'thank|thx', re.UNICODE)}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to find the intent of a message\n",
    "def match_intent(message):\n",
    "    matched_intent = None\n",
    "    for intent, pattern in patterns.items():\n",
    "        # Check if the pattern occurs in the message \n",
    "        if re.search(pattern, message):\n",
    "            matched_intent = intent\n",
    "    return matched_intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a respond function\n",
    "def respond(message):\n",
    "    # Call the match_intent function\n",
    "    intent = match_intent(message)\n",
    "    # Fall back to the default response\n",
    "    key = \"default\"\n",
    "    if intent in responses:\n",
    "        key = intent\n",
    "    return responses[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER : hello!\n",
      "BOT : ['hello', 'hi', 'hey']\n",
      "USER : bye byeee\n",
      "BOT : ['bye', 'farewell']\n",
      "USER : thanks very much!\n",
      "BOT : ['thank', 'thx']\n"
     ]
    }
   ],
   "source": [
    "# Send messages\n",
    "send_message(\"hello!\")\n",
    "send_message(\"bye byeee\")\n",
    "send_message(\"thanks very much!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define find_name()\n",
    "def find_name(message):\n",
    "    name = None\n",
    "    # Create a pattern for checking if the keywords occur\n",
    "    name_keyword = re.compile(\"name|call\")\n",
    "    # Create a pattern for finding capitalized words\n",
    "    name_pattern = re.compile(\"[A-Z]{1}[a-z]*\")\n",
    "    if name_keyword.search(message):\n",
    "        # Get the matching words in the string\n",
    "        name_words = name_pattern.findall(message)\n",
    "        if len(name_words) > 0:\n",
    "            # Return the name if the keywords are present\n",
    "            name = ' '.join(name_words)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define respond()\n",
    "def respond(message):\n",
    "    # Find the name\n",
    "    name = find_name(message)\n",
    "    if name is None:\n",
    "        return \"Hi there!\"\n",
    "    else:\n",
    "        return \"Hello, {0}!\".format(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER : my name is David Copperfield\n",
      "BOT : Hello, David Copperfield!\n",
      "USER : call me Ishmael\n",
      "BOT : Hello, Ishmael!\n",
      "USER : People call me Cassandra\n",
      "BOT : Hello, People Cassandra!\n"
     ]
    }
   ],
   "source": [
    "# Send messages\n",
    "send_message(\"my name is David Copperfield\")\n",
    "send_message(\"call me Ishmael\")\n",
    "send_message(\"People call me Cassandra\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using machine learning with word vectors approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Machine Learning are programs/algos which can get better at a task by being exposed to more data. It is useful for identifying which intent a user message belongs to.\n",
    "- Word vectors try to represent the meaning of words. Words which appear in a similar context have similar vectors. \n",
    "- Training word vectors requires a lot of data. High quality word vectors are available for anyone to use. \n",
    "- We'll be using vectors trained using the GloVe algorithm. It's a cousin of word2vec. \n",
    "- spaCy libary makes it easy for us to work with. \n",
    "- Word vectors tend to have a few hundred dimensions. \n",
    "\n",
    "#### Similarity:\n",
    "- Direction of vectors matters most. \n",
    "- \"Distance\" between words = angle between vectors.\n",
    "- Cosine similarity is typically used (1: same direction, 0: perpendicular, -1: opposite directions)\n",
    "- Similarity measures the closeness based on meaning rather than spelling (cat is more close to dog than can)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc = nlp(\"hello can you help me?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello : [-0.471943    0.89080065 -3.1119015 ]\n",
      "can : [-2.7098207  1.725213  -2.644401 ]\n",
      "you : [-1.3109131 -0.8390915  2.0264437]\n",
      "help : [2.0195212 3.0754364 1.0527022]\n",
      "me : [ 2.116044  -1.7906384  3.7089853]\n",
      "? : [2.5248501  0.36586478 2.486153  ]\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(\"{} : {}\".format(token, token.vector[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat = nlp(\"cat\")\n",
    "can = nlp(\"can\")\n",
    "dog = nlp(\"dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33122889695673313"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.similarity(can)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7344887830914172"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.similarity(dog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCy examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = [' i want to fly from boston at 838 am and arrive in denver at 1110 in the morning',\n",
    " ' what flights are available from pittsburgh to baltimore on thursday morning',\n",
    " ' what is the arrival time in san francisco for the 755 am flight leaving washington',\n",
    " ' cheapest airfare from tacoma to orlando',\n",
    " ' round trip fares from pittsburgh to philadelphia under 1000 dollars',\n",
    " ' i need a flight tomorrow from columbus to minneapolis',\n",
    " ' what kind of aircraft is used on a flight from cleveland to dallas',\n",
    " ' show me the flights from pittsburgh to los angeles on thursday',\n",
    " ' all flights from boston to washington',\n",
    " ' what kind of ground transportation is available in denver',\n",
    " ' show me the flights from dallas to san francisco',\n",
    " ' show me the flights from san diego to newark by way of houston',\n",
    " ' what is the cheapest flight from boston to bwi',\n",
    " ' all flights to baltimore after 6 pm',\n",
    " ' show me the first class fares from boston to denver',\n",
    " ' show me the ground transportation in denver',\n",
    " ' all flights from denver to pittsburgh leaving after 6 pm and before 7 pm',\n",
    " ' i need information on flights for tuesday leaving baltimore for dallas dallas to boston and boston to baltimore',\n",
    " ' please give me the flights from boston to pittsburgh on thursday of next week',\n",
    " ' i would like to fly from denver to pittsburgh on united airlines',\n",
    " ' show me the flights from san diego to newark',\n",
    " ' please list all first class flights on united from denver to baltimore',\n",
    " ' what kinds of planes are used by american airlines',\n",
    " \" i'd like to have some information on a ticket from denver to pittsburgh and atlanta\",\n",
    " \" i'd like to book a flight from atlanta to denver\",\n",
    " ' which airline serves denver pittsburgh and atlanta',\n",
    " \" show me all flights from boston to pittsburgh on wednesday of next week which leave boston after 2 o'clock pm\",\n",
    " ' atlanta ground transportation',\n",
    " ' i also need service from dallas to boston arriving by noon',\n",
    " ' show me the cheapest round trip fare from baltimore to dallas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the spacy model: nlp\n",
    "nlp = spacy.load(\"en\")\n",
    "\n",
    "nlp.vocab.reset_vectors(width=384)\n",
    "\n",
    "# Calculate the length of sentences\n",
    "n_sentences = len(sentences)\n",
    "\n",
    "# Calculate the dimensionality of nlp\n",
    "embedding_dim = nlp.vocab.vectors_length\n",
    "\n",
    "# Initialize the array with zeros: X\n",
    "X = np.zeros((n_sentences, embedding_dim))\n",
    "\n",
    "# Iterate over the sentences\n",
    "for idx, sentence in enumerate(sentences):\n",
    "    # Pass each each sentence to the nlp object to create a document\n",
    "    doc = nlp(sentence)\n",
    "    # Save the document's .vector attribute to the corresponding row in X\n",
    "    X[idx, :] = doc.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 384)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intents and classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A classifier predicts the intent label given a sentence\n",
    "- Fit classifier by tuning it on training data\n",
    "- Evaluate performance on test data\n",
    "- Accuracy: the fraction of labels we predict correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences_train = [\n",
    "  \"i want to fly from boston at 838 am and arrive in denver at 1110 in the morning\",\n",
    "  \"what flights are available from pittsburgh to baltimore on thursday morning\"\n",
    "]\n",
    "\n",
    "labels_train = [\"atis_flight1\", \"atis_flight2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_shape = (len(sentences_train), nlp.vocab.vectors_length)\n",
    "X_train = np.zeros(X_train_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(sentences_train):\n",
    "    doc = nlp(sentence)\n",
    "    X_train[i, :] = doc.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 384)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 384)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 384)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1:].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest neighbor classification\n",
    "- Need training data: Sentences which we've already labeled with their intents\n",
    "- Simplest solution is to look for the labeled example that's most similar and use its intent as a best guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_message = \"\"\"\n",
    "i would like to find a flight from charlotte\n",
    "to las vegas that makes a stop in st. louis\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 384)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = nlp(test_message).vector.reshape(1, -1)\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = [cosine_similarity([X_train[i,:]], test_x) for i in range(len(sentences_train))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'atis_flight1'"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train[np.argmax(scores)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support vector machines (SVM)\n",
    "- Nearest neighbors is very simple - we can do better\n",
    "- SVM/SVC: support vector machine/classifier work really well for classifying intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Import SVC\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "##### Create a support vector classifier\n",
    "# clf = SVC(C = 1)\n",
    "\n",
    "##### Fit the classifier using the training data\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "##### Predict the labels of the test set\n",
    "# y_pred = clf.predict(X_test)\n",
    "\n",
    "##### Count the number of correct predictions\n",
    "# n_correct = 0\n",
    "# for i in range(len(y_test)):\n",
    "#     if y_pred[i] == y_test[i]:\n",
    "#         n_correct += 1\n",
    "\n",
    "# print(\"Predicted {0} correctly out of {1} test examples\".format(n_correct, len(y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity extraction\n",
    "\n",
    "Beyond keywords: context\n",
    "\n",
    "- Keywords don't work for entities you haven't seen before\n",
    "- Use contextual clues: spelling, capitalization, words occurring before/after, pattern recognition\n",
    "\n",
    "Use spacy's pre-built named entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary PERSON\n",
      "Google ORG\n",
      "2009 DATE\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"my friend Mary has worked at Google since 2009\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roles: \n",
    "\n",
    "- I want a flight from Tel Aviv to Bucharest\n",
    "- show me flights to Shanghai from Singapore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pattern_1 = re.compile('.* from (.*) to (.*)')\n",
    "pattern_2 = re.compile('.* to (.*) from (.*)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependency parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc = nlp(\"a flight from Shanghai to Singapore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shanghai, singapore = doc[3], doc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[from, flight]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(shanghai.ancestors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[to, from, flight]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(singapore.ancestors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc = nlp(\"let's see that jacket in red and some blue jeans\")\n",
    "items = [doc[4], doc[10]] \n",
    "colors = [doc[6], doc[9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jacket, jeans]\n"
     ]
    }
   ],
   "source": [
    "print(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[red, blue]\n"
     ]
    }
   ],
   "source": [
    "print(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "color red belongs to item jacket\n",
      "color blue belongs to item jeans\n"
     ]
    }
   ],
   "source": [
    "for color in colors:\n",
    "    for tok in color.ancestors:\n",
    "        if tok in items:\n",
    "            print(\"color {} belongs to item {}\".format(color, tok))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blue = doc[9]\n",
    "red = doc[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[jeans, jacket, see, let]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(blue.ancestors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[in, jacket, see, let]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(red.ancestors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entity recongizer practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DATE': '2010', 'ORG': 'Google', 'PERSON': 'Mary'}\n",
      "{'DATE': '1999', 'ORG': 'MIT', 'PERSON': None}\n"
     ]
    }
   ],
   "source": [
    "# Define included entities\n",
    "include_entities = ['DATE', 'ORG', 'PERSON']\n",
    "\n",
    "# Define extract_entities()\n",
    "def extract_entities(message):\n",
    "    # Create a dict to hold the entities\n",
    "    ents = dict.fromkeys(include_entities)\n",
    "    # Create a spacy document\n",
    "    doc = nlp(message)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in include_entities:\n",
    "            # Save interesting entities\n",
    "            ents[ent.label_] = ent.text\n",
    "    return ents\n",
    "\n",
    "print(extract_entities('friends called Mary who have worked at Google since 2010'))\n",
    "print(extract_entities('people who graduated from MIT in 1999'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rasa NLU\n",
    "\n",
    "- Library for intent recognition and entity extraction\n",
    "- Based on spacy, sklearn, and other libraries\n",
    "- Built-in support for chatbot specific tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasa_nlu.training_data import load_data\n",
    "from rasa_nlu.config import RasaNLUModelConfig\n",
    "from rasa_nlu.model import Trainer\n",
    "from rasa_nlu import config\n",
    "from rasa_nlu.model import Metadata, Interpreter\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data1 = load_data('datasets/rasa/demo-rasa.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "message = \"i want to book a flight to london\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(config.load(\"datasets/rasa/config_spacy.yml\"))\n",
    "trainer.train(training_data1)\n",
    "model_directory = trainer.persist('./projects/default/')  # Returns the directory the model is stored in\n",
    "\n",
    "# where `model_directory points to the folder the model is persisted in\n",
    "interpreter = Interpreter.load(model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entities': [],\n",
       " 'intent': {'confidence': 0.3646582977217032, 'name': 'affirm'},\n",
       " 'intent_ranking': [{'confidence': 0.3646582977217032, 'name': 'affirm'},\n",
       "  {'confidence': 0.347563799497321, 'name': 'restaurant_search'},\n",
       "  {'confidence': 0.1622227660275711, 'name': 'goodbye'},\n",
       "  {'confidence': 0.12555513675340488, 'name': 'greet'}],\n",
       " 'text': 'What to digest later?'}"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.parse(u\"What to digest later?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entities': [{'confidence': 0.6382681283292376,\n",
       "   'end': 25,\n",
       "   'entity': 'cuisine',\n",
       "   'extractor': 'ner_crf',\n",
       "   'start': 18,\n",
       "   'value': 'mexican'},\n",
       "  {'confidence': 0.637001646710072,\n",
       "   'end': 49,\n",
       "   'entity': 'location',\n",
       "   'extractor': 'ner_crf',\n",
       "   'start': 44,\n",
       "   'value': 'north'}],\n",
       " 'intent': {'confidence': 0.8486427791268274, 'name': 'restaurant_search'},\n",
       " 'intent_ranking': [{'confidence': 0.8486427791268274,\n",
       "   'name': 'restaurant_search'},\n",
       "  {'confidence': 0.07106318630745903, 'name': 'goodbye'},\n",
       "  {'confidence': 0.04582848103536911, 'name': 'affirm'},\n",
       "  {'confidence': 0.034465553530344195, 'name': 'greet'}],\n",
       " 'text': \"I'm looking for a Mexican restaurant in the North of town\"}"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.parse(u\"I'm looking for a Mexican restaurant in the North of town\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Data-efficient entity recognition\n",
    "Most systems for extracting entities from text are built to extract 'Universal' things like names, dates, and places. But you probably don't have enough training data for your bot to make these systems perform well!\n",
    "\n",
    "We'll activate the MITIE entity recogniser inside rasa to extract restaurants-related entities using a very small amount of training data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
