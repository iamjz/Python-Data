{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov chains\n",
    "\n",
    "A Markov chain is a system whose evolution is described by a stoachastic process. If the structure of such process is that dependence of current state with respect to entire past is completely captured by the dependence on the last sample, also known as the markov property, then this process is a markov chain\n",
    "\n",
    "The markov property is mathematically expressed by the following conditional independence:\n",
    "(https://en.wikipedia.org/wiki/Conditional_independence):\n",
    "\n",
    "$$ P(X_{n+1}|X_n, X_{n-1}, ... X_1) = P(X_{n+1}|X_n) $$\n",
    "\n",
    "That is, the probability of next state within a process is the governed only by the current state.\n",
    "\n",
    "http://setosa.io/ev/markov-chains/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy linear algebra package\n",
    "\n",
    "Example:\n",
    "\n",
    "Consider a radio station playing 2 genres of songs, which we label as 0 and 1. From time to time, the radio station may switch genre or keep playing songs from the same genre. These transition probabilities can be collected in a matrix (known as the transition matrix). \n",
    "\n",
    "The markov chain can be used to answer questions such as:\n",
    "\n",
    "* What's the probability of current state at any moment? Or likelihood of each genre being played?\n",
    "    * This is asking for the stationary distribution\n",
    "* What's the average time for the system to go back to each state? Or how often does it play the same genre again?\n",
    "\n",
    "To answer these questions, it's necessary to first realize that it's possible that some states could only occur a finite number of times...ie: there may be states that don't recur.\n",
    "\n",
    "A markov chain is said to be ergodic when we can substitute time averages for ensemble averages:\n",
    "$$ \\lim _ {k \\to \\infty } {\\frac{1}{\\frac{1}{k} \\sum_{k'=1}^{k}{T_i(k')} }} = \\frac {1}{E[T_i(k)]}$$\n",
    "\n",
    "where $T_i(k)$ is time elapses between (k-1)-th and k-th return to state i.\n",
    "\n",
    "The **ergodicity theorem** states that\n",
    "\n",
    "1. If a **stationary distribution** $\\pi$ exists for a Markov Chain, it's ergodic.\n",
    "2. Such **stationary distribution** is independent of initial distribution $\\pi_0$ of Markov Chain if it's ergodic.\n",
    "\n",
    "Therefore, assuming existence of a stationary distribution of the Markov Chain,\n",
    "the solution can be found using the **power method**:\n",
    "\n",
    "$$ \\pi = \\lim_{n \\to \\infty }{\\pi_0 P^{n}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose tha radio station has 1/3 probability of switching genre and 2/3 probability of staying in the same genre. Based on the fact that this is symmetric with respect to each genre, we should intuitively have probability of tuning into each genre equal to 1/2. Now, let's solve using the power method and verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transition matrix\n",
    "P = np.array([[2/3, 1/3], \n",
    "              [1/3, 2/3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initial distribution can be anything that sums up to 1\n",
    "pi0 = np.array([0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5,  0.5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute stationary distribution - power method\n",
    "np.dot(pi0, np.linalg.matrix_power(P, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the probability of state 0 and 1 are both 0.5. But what if probability of switching from 0 to 1 is 1/4 and probability of switching from 1 to 0 is 1/3 so that this radio station baises towards one genre? We can now answer this less trivial question as well with the power method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transition matrix\n",
    "P = np.array([[3/4, 1/4], \n",
    "                [1/3, 2/3]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initial distribution can be anything that sums up to 1\n",
    "pi0 = np.array([0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.57142857,  0.42857143])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute stationary state - power method\n",
    "np.dot(pi0, np.linalg.matrix_power(P, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a new probability of each genre given the changed transition probabilities. Intuitively, we are less likely to switch away from genre 0 to 1 than vice versa and therefore more likely to hear a song from genre 0. Another tool for solving this problem is eigen-decomposition due to Perron-Frobenius theorem.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Perronâ€“Frobenius_theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some random 5x5 transition matrix\n",
    "P = np.random.rand(5, 5)\n",
    "P /= P.sum(axis = 1)[:, np.newaxis] # normalization along axis 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.24792737  0.23929169  0.17282013  0.2065674   0.13339341]\n"
     ]
    }
   ],
   "source": [
    "# compute stationary score - power method\n",
    "pi0 = np.random.rand(5)\n",
    "pi0 /= pi0.sum()\n",
    "a = np.dot(pi0, np.linalg.matrix_power(P, 50))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.24792737  0.23929169  0.17282013  0.2065674   0.13339341]\n"
     ]
    }
   ],
   "source": [
    "# compute stationary state - eigen decomposition\n",
    "L, Q = np.linalg.eig(P.T)\n",
    "\n",
    "# pick eigenvector whose corresponding eigenvalue is closest to 1\n",
    "b = Q[:, np.argmin(abs(L - 1.0))].real\n",
    "\n",
    "# normalize into a probability distribution\n",
    "b /= b.sum()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an implementation of the power method with tensorflow. Currently, neither matrix power or eigen-decomposition is supported but we may still want to leverage tensorflow's high scalability to process datasets. This algo will use the divide and conquer strategy to reduce time complexity as well as space complexity for representing such computation in tensorflow. The advantage is that this program will utilize GPU when available and you wouldn't need to change anything to let that happen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute stationary state - power method\n",
    "\n",
    "def mat_power(M, n):\n",
    "    \"\"\" Construct a graph that raises square matrix M to n-th power where n>=1\n",
    "    This generates a computational graph with space complexity O(log(n)).\n",
    "    \"\"\"\n",
    "    \n",
    "    assert n >= 1\n",
    "    \n",
    "    # trivial cases\n",
    "    \n",
    "    if n == 2:\n",
    "        return tf.matmul(M, M)\n",
    "    elif n == 1:\n",
    "        return M\n",
    "    \n",
    "    # divide and conquer\n",
    "    A = mat_power(M, n//2)\n",
    "    A2 = tf.matmul(A, A)\n",
    "    \n",
    "    if n &1: # odd power\n",
    "        return tf.matmul(A2, M)\n",
    "    else: # even power\n",
    "        return A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stationary_state(P):\n",
    "    pi0 = tf.constant(np.ones((1, len(P)))/len(P))\n",
    "    transition_matrix = tf.constant(P)\n",
    "    stationary_state = tf.squeeze(tf.matmul(pi0, mat_power(transition_matrix, 50)))\n",
    "    with tf.Session() as sess:\n",
    "        return sess.run(stationary_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.24792737  0.23929169  0.17282013  0.2065674   0.13339341]\n"
     ]
    }
   ],
   "source": [
    "a = get_stationary_state(P)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(a, b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
