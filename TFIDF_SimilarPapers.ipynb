{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build up my corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "\n",
    "for f in os.listdir(\"datasets/papers/\"):\n",
    "    if (f.endswith(\".txt\")):\n",
    "        with open(os.path.join(\"datasets/papers\", f), \"r\", encoding = \"utf8\") as paper:\n",
    "            corpus.append((f, paper.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('100226.txt', 'Coherent functions and program checkers'),\n",
       " ('100228.txt', 'The wakeup problem'),\n",
       " ('100231.txt', 'Efficient robust parallel computations'),\n",
       " ('100262.txt', 'An optimal algorithm for on-line bipartite matching'),\n",
       " ('100269.txt',\n",
       "  'One-way functions are necessary and sufficient for secure signatures'),\n",
       " ('100270.txt', 'Pseudo-random generators under uniform assumptions'),\n",
       " ('100272.txt', 'Witness indistinguishable and witness hiding protocols'),\n",
       " ('100273.txt',\n",
       "  'Public-key cryptosystems provably secure against chosen ciphertext attacks'),\n",
       " ('100287.txt', 'The round complexity of secure protocols')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the TF-IDF vectorizer and matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=0,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = TfidfVectorizer(analyzer = \"word\", \n",
    "                         ngram_range = (1, 3), \n",
    "                         min_df = 0, \n",
    "                         stop_words = \"english\")\n",
    "\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5801x41397 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 77828 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix = tf.fit_transform([content for file, content in corpus])\n",
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a function to find similar documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar(matrix, index, top_n = 5):\n",
    "    cosine_similarities = linear_kernel(matrix[index: index + 1], matrix).flatten()\n",
    "    related_docs_indices = [i for i in cosine_similarities.argsort()[::-1] if i != index]\n",
    "    return [(index, cosine_similarities[index]) for index in related_docs_indices][0:top_n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's test it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1034226.txt', 'Disk Scrubbing in Large Archival Storage Systems')\n",
      "============================================================================\n",
      "0.206014472291 ('276683.txt', 'Archival storage for digital libraries')\n",
      "0.183158767923 ('651321.txt', 'Venti: A New Approach to Archival Storage')\n",
      "0.169082360056 ('651308.txt', 'Enabling the Archival Storage of Signed Documents')\n",
      "0.163059191107 ('6721.txt', 'Modelling storage systems')\n",
      "0.154747351567 ('1098163.txt', 'Disk Infant Mortality in Large Storage Systems')\n"
     ]
    }
   ],
   "source": [
    "k = 69\n",
    "\n",
    "print(corpus[k])\n",
    "print(\"============================================================================\")\n",
    "\n",
    "for index, score in find_similar(tfidf_matrix, k):\n",
    "    print(score, corpus[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1592576.txt', 'VL2: a scalable and flexible data center network')\n",
      "============================================================================\n",
      "0.368580782349 ('1402967.txt', 'A scalable, commodity data center network architecture')\n",
      "0.17191681242 ('2465363.txt', 'MDCC: multi-data center consistency')\n",
      "0.0842481596981 ('365690.txt', 'Determining a computing center environment')\n",
      "0.0728900387948 ('317906.txt', 'Flexible type analysis')\n",
      "0.0610049952954 ('383072.txt', 'A scalable content-addressable network')\n"
     ]
    }
   ],
   "source": [
    "k = 1000\n",
    "\n",
    "print(corpus[k])\n",
    "print(\"============================================================================\")\n",
    "\n",
    "for index, score in find_similar(tfidf_matrix, k):\n",
    "    print(score, corpus[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('100226.txt', 'Coherent functions and program checkers')\n",
      "============================================================================\n",
      "0.102871883709 ('802557.txt', 'Program slicing')\n",
      "0.0831211600727 ('74871.txt', 'Mirage: a coherent distributed shared memory design')\n",
      "0.0811169433187 ('176577.txt', 'A coherent distributed file cache with directory write-behind')\n",
      "0.0772474014488 ('324179.txt', 'Linear hash functions')\n",
      "0.0747132843379 ('6503.txt', 'How to construct random functions')\n"
     ]
    }
   ],
   "source": [
    "k = 1\n",
    "\n",
    "print(corpus[k])\n",
    "print(\"============================================================================\")\n",
    "\n",
    "for index, score in find_similar(tfidf_matrix, k):\n",
    "    print(score, corpus[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1057980.txt', 'Optimistic replication')\n",
      "============================================================================\n",
      "0.455880427813 ('675975.txt', 'Optimistic Replication for Internet Data Services')\n",
      "0.303054286223 ('879308.txt', 'Optimistic Active Replication')\n",
      "0.197371551772 ('758421.txt', 'Optimistic Atomic Broadcast')\n",
      "0.185949033747 ('831121.txt', 'Optimistic Byzantine Agreement')\n",
      "0.174990993836 ('2162347.txt', 'Optimistic generic broadcast')\n"
     ]
    }
   ],
   "source": [
    "k = 129\n",
    "\n",
    "print(corpus[k])\n",
    "print(\"============================================================================\")\n",
    "\n",
    "for index, score in find_similar(tfidf_matrix, k):\n",
    "    print(score, corpus[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('141970.txt', 'The Apertos reflective operating system: the concept and its implementation')\n",
      "============================================================================\n",
      "0.111595933688 ('361161.txt', 'Monitors: an operating system structuring concept')\n",
      "0.0998146193129 ('1173748.txt', 'Reflective program generation with patterns')\n",
      "0.0981128385031 ('2156790.txt', 'A type system for reflective program generators')\n",
      "0.0873313154276 ('21853.txt', 'Operating systems: design and implementation')\n",
      "0.0758885399523 ('231070.txt', 'The design and implementation of the 4.4BSD operating system')\n"
     ]
    }
   ],
   "source": [
    "k = 888\n",
    "\n",
    "print(corpus[k])\n",
    "print(\"============================================================================\")\n",
    "\n",
    "for index, score in find_similar(tfidf_matrix, k):\n",
    "    print(score, corpus[index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
